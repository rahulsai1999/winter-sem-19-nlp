{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ly'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "stemmerPorter=PorterStemmer()\n",
    "stemmerPorter.stem('Lying')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wat'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import LancasterStemmer\n",
    "stemmerLancaster=LancasterStemmer()\n",
    "stemmerLancaster.stem('watering')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import RegexpStemmer\n",
    "stemmerRegex=RegexpStemmer('ing')\n",
    "stemmerRegex.stem('singing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "englishSnow=SnowballStemmer('english')\n",
    "len(SnowballStemmer.languages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mang'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frenchStemmer=SnowballStemmer('french')\n",
    "frenchStemmer.stem('manges')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sitzt'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "germanStemmer=SnowballStemmer('german')\n",
    "germanStemmer.stem('sitzt') # actual stem => sitz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance of various stemmers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the performance of various stemmers using a ambigous word-list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_words=['association','country','organizing','generous','publisher','importer','namely']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['associ', 'countri', 'organ', 'gener', 'publish', 'import', 'name']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[stemmerPorter.stem(i) for i in comp_words] # 3 out of 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['assocy', 'country', 'org', 'gen', 'publ', 'import', 'nam']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[stemmerLancaster.stem(i) for i in comp_words] # 2 out of 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['associ', 'countri', 'organ', 'generous', 'publish', 'import', 'name']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[englishSnow.stem(i) for i in comp_words] # 3 out of 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good -> good\n",
      "Solving -> solve\n",
      "Cacti -> cactus\n"
     ]
    }
   ],
   "source": [
    "# pos=a for adjective\n",
    "print(\"Good -> {}\".format(lemmatizer.lemmatize(\"better\",pos='a'))) \n",
    "      \n",
    "# pos=v for verb\n",
    "print(\"Solving -> {}\".format(lemmatizer.lemmatize(\"solving\",pos='v')))\n",
    "\n",
    "# pos=n for noun\n",
    "print(\"Cacti -> {}\".format(lemmatizer.lemmatize(\"cacti\",pos='n')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Stemming and Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "example=\"\"\"\"Jordan in 2011 ,Jordan worked as a child model for several companies \n",
    "and brands, including Modell's sporting goods and Toys 'R' Us, before deciding \n",
    "to embark on a career as an actor. He launched his career as a professional \n",
    "actor in 1999, when he appeared briefly in single episodes of the television \n",
    "series Cosby and The Sopranos. His first principal film role followed in 2001 \n",
    "when he was featured in Hardball, which starred Keanu Reeves.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens=example.split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmedWords=[stemmerPorter.stem(token) for token in tokens]  # list comprehension for stemming words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizedWords=[lemmatizer.lemmatize(token) for token in tokens]  # list comprehension for lemmatizing words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "difference=list(set(lemmatizedWords)-set(stemmedWords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(difference) # difference between the stemmed words and lemmatized words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectoriser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cVect=CountVectorizer(stop_words=\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "example=example.split(\".\")[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "words=cVect.fit_transform(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 27)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.shape # rows and columns of the matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cVect.get_feature_names()) # features in the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'jordan': 15,\n",
       " '2011': 1,\n",
       " 'worked': 26,\n",
       " 'child': 7,\n",
       " 'model': 17,\n",
       " 'companies': 8,\n",
       " 'brands': 4,\n",
       " 'including': 14,\n",
       " 'modell': 18,\n",
       " 'sporting': 23,\n",
       " 'goods': 13,\n",
       " 'toys': 25,\n",
       " 'deciding': 10,\n",
       " 'embark': 11,\n",
       " 'career': 6,\n",
       " 'actor': 2,\n",
       " 'launched': 16,\n",
       " 'professional': 19,\n",
       " '1999': 0,\n",
       " 'appeared': 3,\n",
       " 'briefly': 5,\n",
       " 'single': 21,\n",
       " 'episodes': 12,\n",
       " 'television': 24,\n",
       " 'series': 20,\n",
       " 'cosby': 9,\n",
       " 'sopranos': 22}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cVect.vocabulary_ # the list of features and their number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfVect=TfidfVectorizer(smooth_idf=False,analyzer='word')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "words=tfVect.fit_transform(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'jordan': 23,\n",
       " 'in': 21,\n",
       " '2011': 1,\n",
       " 'worked': 41,\n",
       " 'as': 6,\n",
       " 'child': 11,\n",
       " 'model': 25,\n",
       " 'for': 17,\n",
       " 'several': 31,\n",
       " 'companies': 12,\n",
       " 'and': 4,\n",
       " 'brands': 8,\n",
       " 'including': 22,\n",
       " 'modell': 26,\n",
       " 'sporting': 34,\n",
       " 'goods': 18,\n",
       " 'toys': 38,\n",
       " 'us': 39,\n",
       " 'before': 7,\n",
       " 'deciding': 14,\n",
       " 'to': 37,\n",
       " 'embark': 15,\n",
       " 'on': 28,\n",
       " 'career': 10,\n",
       " 'an': 3,\n",
       " 'actor': 2,\n",
       " 'he': 19,\n",
       " 'launched': 24,\n",
       " 'his': 20,\n",
       " 'professional': 29,\n",
       " '1999': 0,\n",
       " 'when': 40,\n",
       " 'appeared': 5,\n",
       " 'briefly': 9,\n",
       " 'single': 32,\n",
       " 'episodes': 16,\n",
       " 'of': 27,\n",
       " 'the': 36,\n",
       " 'television': 35,\n",
       " 'series': 30,\n",
       " 'cosby': 13,\n",
       " 'sopranos': 33}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfVect.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1999': 1.6931471805599454, '2011': 1.6931471805599454, 'actor': 1.0, 'an': 1.6931471805599454, 'and': 1.0, 'appeared': 1.6931471805599454, 'as': 1.0, 'before': 1.6931471805599454, 'brands': 1.6931471805599454, 'briefly': 1.6931471805599454, 'career': 1.0, 'child': 1.6931471805599454, 'companies': 1.6931471805599454, 'cosby': 1.6931471805599454, 'deciding': 1.6931471805599454, 'embark': 1.6931471805599454, 'episodes': 1.6931471805599454, 'for': 1.6931471805599454, 'goods': 1.6931471805599454, 'he': 1.6931471805599454, 'his': 1.6931471805599454, 'in': 1.0, 'including': 1.6931471805599454, 'jordan': 1.6931471805599454, 'launched': 1.6931471805599454, 'model': 1.6931471805599454, 'modell': 1.6931471805599454, 'of': 1.6931471805599454, 'on': 1.6931471805599454, 'professional': 1.6931471805599454, 'series': 1.6931471805599454, 'several': 1.6931471805599454, 'single': 1.6931471805599454, 'sopranos': 1.6931471805599454, 'sporting': 1.6931471805599454, 'television': 1.6931471805599454, 'the': 1.6931471805599454, 'to': 1.6931471805599454, 'toys': 1.6931471805599454, 'us': 1.6931471805599454, 'when': 1.6931471805599454, 'worked': 1.6931471805599454}\n"
     ]
    }
   ],
   "source": [
    "print(dict(zip(tfVect.get_feature_names(),tfVect.idf_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The words which occur more number of times have more IDF value"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
